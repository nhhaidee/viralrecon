
/*
 * -------------------------------------------------
 *  Helper functions
 * -------------------------------------------------
 */
def nfcoreHeader() {
    // Log colors ANSI codes
    c_black = params.monochrome_logs ? '' : "\033[0;30m";
    c_blue = params.monochrome_logs ? '' : "\033[0;34m";
    c_cyan = params.monochrome_logs ? '' : "\033[0;36m";
    c_dim = params.monochrome_logs ? '' : "\033[2m";
    c_green = params.monochrome_logs ? '' : "\033[0;32m";
    c_purple = params.monochrome_logs ? '' : "\033[0;35m";
    c_reset = params.monochrome_logs ? '' : "\033[0m";
    c_white = params.monochrome_logs ? '' : "\033[0;37m";
    c_yellow = params.monochrome_logs ? '' : "\033[0;33m";

    return """    -${c_dim}--------------------------------------------------${c_reset}-
                                            ${c_green},--.${c_black}/${c_green},-.${c_reset}
    ${c_blue}        ___     __   __   __   ___     ${c_green}/,-._.--~\'${c_reset}
    ${c_blue}  |\\ | |__  __ /  ` /  \\ |__) |__         ${c_yellow}}  {${c_reset}
    ${c_blue}  | \\| |       \\__, \\__/ |  \\ |___     ${c_green}\\`-._,-`-,${c_reset}
                                            ${c_green}`._,._,\'${c_reset}
    ${c_purple}  nf-core/viralrecon v${workflow.manifest.version}${c_reset}
    -${c_dim}--------------------------------------------------${c_reset}-
    """.stripIndent()
}

def checkHostname() {
    def c_reset = params.monochrome_logs ? '' : "\033[0m"
    def c_white = params.monochrome_logs ? '' : "\033[0;37m"
    def c_red = params.monochrome_logs ? '' : "\033[1;91m"
    def c_yellow_bold = params.monochrome_logs ? '' : "\033[1;93m"
    if (params.hostnames) {
        def hostname = "hostname".execute().text.trim()
        params.hostnames.each { prof, hnames ->
            hnames.each { hname ->
                if (hostname.contains(hname) && !workflow.profile.contains(prof)) {
                    log.error "====================================================\n" +
                            "  ${c_red}WARNING!${c_reset} You are running with `-profile $workflow.profile`\n" +
                            "  but your machine hostname is ${c_white}'$hostname'${c_reset}\n" +
                            "  ${c_yellow_bold}It's highly recommended that you use `-profile $prof${c_reset}`\n" +
                            "============================================================"
                }
            }
        }
    }
}

def helpMessage() {
    log.info nfcoreHeader()
    log.info"""

    Usage:

    The typical command for running the pipeline is as follows:

    nextflow run nf-core/viralrecon --input samplesheet.csv --genome 'MN908947.3' -profile docker

    Mandatory arguments
      --input [file]                    Comma-separated file containing information about the samples in the experiment (see docs/usage.md)
      --fasta [file]                    Path to fasta reference for viral genome. Mandatory when --genome not supplied
      --amplicon_bed [file]             Path to BED file containing amplicon positions. Mandatory when calling variants with --protocol amplicon
      --amplicon_fasta [file]           Path to fasta file containing amplicon sequences. Mandatory when performing assembly with --protocol amplicon
      -profile [str]                    Configuration profile to use. Can use multiple (comma separated)
                                        Available: conda, docker, singularity, test, awsbatch, <institute> and more

    Generic
      --protocol [str]                  Specifies the type of protocol used for sequencing i.e. 'metagenomic' or 'amplicon' (Default: 'metagenomic')

    Trim Primers
      --trim_primer [bool]              Trim Primer using FBGIO (Default: 'true')

    SRA download
      --save_sra_fastq [bool]           Save FastQ files created from SRA identifiers in the results directory (Default: false)
      --skip_sra [bool]                 Skip steps involving the download and validation of FastQ files using SRA identifiers (Default: false)

    References                          If not specified in the configuration file or you wish to overwrite any of the references
      --genome [str]                    Name of genome reference key for viral genome (Default: '')
      --gff [file]                      Full path to viral gff annotation file (Default: '')
      --save_reference [bool]           If generated by the pipeline save the Bowtie2 indices in the results directory (Default: false)

    Read trimming
      --cut_mean_quality [int]          The mean quality requirement option shared by fastp cut_front, cut_tail or cut_sliding options. Range: 1~36 (Default: 30 (Q30))
      --qualified_quality_phred [int]   The quality value that a base is qualified. Default 30 means phred quality >=Q30 is qualified (Default: 30)
      --unqualified_percent_limit [int] Percentage of bases that are allowed to be unqualified (0~100) (Default: 10)
      --min_trim_length [int]           Reads shorter than this length after trimming will be discarded (Default: 50)
      --skip_adapter_trimming [bool]    Skip the adapter trimming step with fastp (Default: false)
      --skip_amplicon_trimming [bool]   Skip the amplicon trimming step with Cutadapt (Default: false)
      --save_trimmed [bool]             Save the trimmed FastQ files in the results directory (Default: false)

    Kraken2
      --kraken2_db [file]               Full path to Kraken2 database built from host genome (Default: kraken2_human.tar.gz hosted on Zenodo)
      --kraken2_db_name [str]           Name of host genome for building Kraken2 database (Default: 'human')
      --kraken2_use_ftp [bool]          Use FTP instead of rsync when building kraken2 databases (Default: false)
      --save_kraken2_fastq [bool]       Save the host and viral fastq files in the results directory (Default: false)
      --skip_kraken2 [bool]             Skip Kraken2 process for removing host classified reads (Default: false)

    Variant calling
      --callers [str]                   Specify which variant calling algorithms you would like to use (Default: 'varscan2,ivar,bcftools')
      --min_mapped_reads [int]          Minimum number of mapped reads below which samples are removed from further processing (Default: 1000)
      --ivar_trim_noprimer [bool]       Unset -e parameter for iVar trim. Reads with primers are included by default (Default: false)
      --ivar_trim_min_len [int]         Minimum length of read to retain after trimming (Default: 20)
      --ivar_trim_min_qual [int]        Minimum quality threshold for sliding window to pass (Default: 20)
      --ivar_trim_window_width [int]    Width of sliding window (Default: 4)
      --filter_dups [bool]              Remove duplicate reads from alignments as identified by picard MarkDuplicates (Default: false)
      --filter_unmapped [bool]          Remove unmapped reads from alignments (Default: false)
      --mpileup_depth [int]             SAMTools mpileup max per-file depth (Default: 0)
      --min_base_qual [int]             When performing variant calling skip bases with baseQ/BAQ smaller than this number (Default: 20)
      --min_coverage [int]              When performing variant calling skip positions with an overall read depth smaller than this number (Default: 10)
      --min_allele_freq [float]         Minimum allele frequency threshold for calling variants (Default: 0.25)
      --max_allele_freq [float]         Maximum allele frequency threshold for filtering variant calls (Default: 0.75)
      --varscan2_strand_filter [bool]   Ignore Varscan 2 variants with >90% support on one strand (Default: true)
      --amplicon_left_suffix [str]      Suffix used in name field of --amplicon_bed to indicate left primer position (Default: '_LEFT')
      --amplicon_right_suffix [str]     Suffix used in name field of --amplicon_bed to indicate right primer position (Default: '_RIGHT')
      --save_align_intermeds [bool]     Save the intermediate BAM files from the alignment steps (Default: false)
      --save_mpileup [bool]             Save MPileup files generated during variant calling (Default: false)
      --skip_markduplicates [bool]      Skip picard MarkDuplicates step (Default: false)
      --skip_picard_metrics [bool]      Skip Picard CollectMultipleMetrics and CollectWgsMetrics (Default: false)
      --skip_mosdepth [bool]            Skip genome-wide and amplicon coverage plot generation from mosdepth output (Default: false)
      --skip_snpeff [bool]              Skip SnpEff and SnpSift annotation of variants (Default: false)
      --skip_variants_quast [bool]      Skip generation of QUAST aggregated report for consensus sequences (Default: false)
      --skip_variants [bool]            Skip variant calling steps in the pipeline (Default: false)

    De novo assembly
      --assemblers [str]                Specify which assembly algorithms you would like to use (Default: 'spades,metaspades,unicycler,minia')
      --minia_kmer [int]                Kmer size to use when running minia (Default: 31)
      --skip_blast [bool]               Skip blastn of assemblies relative to reference genome (Default: false)
      --skip_abacas [bool]              Skip ABACAS process for assembly contiguation (Default: false)
      --skip_plasmidid [bool]           Skip assembly report generation by PlasmidID (Default: false)
      --skip_vg [bool]                  Skip variant graph creation and variant calling relative to reference (Default: false)
      --skip_assembly_quast [bool]      Skip generation of QUAST aggregated report for assemblies (Default: false)
      --skip_assembly [bool]            Skip assembly steps in the pipeline (Default: false)

    QC
      --skip_fastqc [bool]              Skip FastQC (Default: false)
      --skip_multiqc [bool]             Skip MultiQC (Default: false)

    Other options:
      --outdir [file]                   The output directory where the results will be saved
      --email [email]                   Set this parameter to your e-mail address to get a summary e-mail with details of the run sent to you when the workflow exits
      --email_on_fail [email]           Same as --email, except only send mail if the workflow is not successful
      --max_multiqc_email_size [str]    Theshold size for MultiQC report to be attached in notification email. If file generated by pipeline exceeds the threshold, it will not be attached (Default: 25MB)
      -name [str]                       Name for the pipeline run. If not specified, Nextflow will automatically generate a random mnemonic

    AWSBatch options:
      --awsqueue [str]                  The AWSBatch JobQueue that needs to be set when running on AWSBatch
      --awsregion [str]                 The AWS Region for your AWS Batch job to run on
      --awscli [str]                    Path to the AWS CLI tool
    """.stripIndent()
}


def validate_sample_sheet(LinkedHashMap sample) {
    def sample_id = sample.sample_id
    def single_end = sample.single_end.toBoolean()
    def is_sra = sample.is_sra.toBoolean()
    def is_ftp = sample.is_ftp.toBoolean()
    def fastq_1 = sample.fastq_1
    def fastq_2 = sample.fastq_2
    def md5_1 = sample.md5_1
    def md5_2 = sample.md5_2

    def array = []
    if (!is_sra) {
        if (single_end) {
            array = [ sample_id, single_end, is_sra, is_ftp, [ file(fastq_1, checkIfExists: true) ] ]
        } else {
            array = [ sample_id, single_end, is_sra, is_ftp, [ file(fastq_1, checkIfExists: true), file(fastq_2, checkIfExists: true) ] ]
        }
    } else {
        array = [ sample_id, single_end, is_sra, is_ftp, [ fastq_1, fastq_2 ], [ md5_1, md5_2 ] ]
    }

    return array
}
// Print warning if viral genome fasta has more than one sequence
def CheckFasta(ch_fasta){
    def count = 0
    ch_fasta.withReader { reader ->
        while (line = reader.readLine()) {
            if (line.contains('>')) {
                count++
                if (count > 1) {
                    log.info "[nf-core/viralrecon] WARNING: This pipeline does not support multi-fasta genome files. Please amend the '--fasta' parameter."
                    break
                }
            }
        }
    }
}

// Function to check if running offline
def isOffline() {
    try {
        return NXF_OFFLINE as Boolean
    }
    catch( Exception e ) {
        return false
    }
}

def get_mapped_from_flagstat(flagstat) {
    def mapped = 0
    flagstat.eachLine { line ->
        if (line.contains(' mapped (')) {
            mapped = line.tokenize().first().toInteger()
        }
    }
    return mapped
}

def check_mapped(sample, flagstat, min_mapped_reads) {
    pass_mapped_reads = [:]
    fail_mapped_reads = [:]
    mapped = get_mapped_from_flagstat(flagstat)
    c_reset = params.monochrome_logs ? '' : "\033[0m";
    c_green = params.monochrome_logs ? '' : "\033[0;32m";
    c_red = params.monochrome_logs ? '' : "\033[0;31m";
    if (mapped < min_mapped_reads.toInteger()) {
        log.info ">${c_red}>>>> $sample FAILED MAPPED READ THRESHOLD: ${mapped} < ${params.min_mapped_reads}. IGNORING FOR FURTHER DOWNSTREAM ANALYSIS! <<<<${c_reset}<"
        fail_mapped_reads[sample] = mapped
        return false
    } else {
        //log.info "-${c_green}           Passed mapped read threshold > bowtie2 ($sample)   >> ${mapped} <<${c_reset}"
        pass_mapped_reads[sample] = mapped
        return true
    }
}
